{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_GaqKgQjSk"
      },
      "source": [
        "# 3 Convolutional Neural Network for Skin Lesion Classification using PyTorch\n",
        "\n",
        "In this tutorial, we'll build a Convolutional Neural Network (CNN) using PyTorch to classify skin lesions from the HAM10000 dataset. This dataset contains 10,000 dermatoscopic images of common pigmented skin lesions across seven diagnostic categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsCYY489mFvB"
      },
      "source": [
        "## 3.1 Downloading the dataset\n",
        "\n",
        "The zipped dataset is about 3 GB in size, so the download may take a few minutes..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! curl -L -o skin-cancer-mnist-ham10000.zip https://www.kaggle.com/api/v1/datasets/download/kmader/skin-cancer-mnist-ham10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MkDHMXESRBQ"
      },
      "outputs": [],
      "source": [
        "# !unzip skin-cancer-mnist-ham10000.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Importing and initial setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AppNRcbvQi5Q"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages (run this if needed)\n",
        "# !pip install torch torchvision pandas matplotlib seaborn scikit-learn pillow tqdm\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhGgRKLyQr8d"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyyAjuNkQ0vd"
      },
      "source": [
        "## 3.3 Working with image data\n",
        "\n",
        "### 3.3.1 Exploring the dataset\n",
        "\n",
        "The HAM10000 dataset consists of 10,015 dermatoscopic images across 7 different categories:\n",
        "- Melanocytic nevi (nv)\n",
        "- Melanoma (mel)\n",
        "- Benign keratosis-like lesions (bkl)\n",
        "- Basal cell carcinoma (bcc)\n",
        "- Actinic keratoses (akiec)\n",
        "- Vascular lesions (vasc)\n",
        "- Dermatofibroma (df)\n",
        "\n",
        "Let's first explore the metadata:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzX8_yleQr-9"
      },
      "outputs": [],
      "source": [
        "# Load the metadata\n",
        "metadata = pd.read_csv('HAM10000_metadata.csv')\n",
        "\n",
        "# Display first few rows\n",
        "print(metadata.head())\n",
        "\n",
        "# Check class distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='dx', data=metadata)\n",
        "plt.title('Distribution of Skin Lesion Classes')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dePzxwCYQsBH"
      },
      "outputs": [],
      "source": [
        "class_counts = metadata['dx'].value_counts()\n",
        "print(\"Class distribution:\")\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"{class_name}: {count} images ({count/len(metadata)*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M58rRdEUD_P"
      },
      "source": [
        "### 3.3.2 Loading the dataset\n",
        "\n",
        "Now, let's create a custom PyTorch dataset for loading the HAM10000 images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgSRF0dVQsDH"
      },
      "outputs": [],
      "source": [
        "class SkinLesionDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (pandas.DataFrame): Dataframe with image metadata\n",
        "            image_dir (string): Directory with all the images\n",
        "            transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Create a mapping from diagnosis to integer label\n",
        "        self.classes = sorted(df['dx'].unique())\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Get image ID and path\n",
        "        img_id = self.df.iloc[idx]['image_id']\n",
        "        # Check both folders since images are split between them\n",
        "        img_path = os.path.join(self.image_dir, 'HAM10000_images_part_1', f\"{img_id}.jpg\")\n",
        "        if not os.path.exists(img_path):\n",
        "            img_path = os.path.join(self.image_dir, 'HAM10000_images_part_2', f\"{img_id}.jpg\")\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Get label\n",
        "        diagnosis = self.df.iloc[idx]['dx']\n",
        "        label = self.class_to_idx[diagnosis]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.3 Adding transformations\n",
        "\n",
        "To make our model more robust, and to augment the dataset, we can apply some transformations to the images. These transformations include resizing, random cropping, and normalization. We will also convert the images to PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdqRcxq_QsFb"
      },
      "outputs": [],
      "source": [
        "# Define data transformations\n",
        "# Data augmentation is done only for training dataset\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Normalizing pixels based on ImageNet's average RGB values\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.4 Splitting the dataset and creating data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPPTKc1rQsHe"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(metadata, test_size=0.2, random_state=42, stratify=metadata['dx'])\n",
        "\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SkinLesionDataset(\n",
        "    df=train_df,\n",
        "    image_dir='.',  # Adjust this path as needed\n",
        "    transform=data_transforms['train']\n",
        ")\n",
        "\n",
        "val_dataset = SkinLesionDataset(\n",
        "    df=val_df,\n",
        "    image_dir='.',  # Adjust this path as needed\n",
        "    transform=data_transforms['val']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY5NgeqeQi7Y"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "# Get class names for reference\n",
        "class_names = train_dataset.classes\n",
        "print(f\"Class names: {class_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXuRoZDuUSUw"
      },
      "source": [
        "## 3.4 Training a CNN Model\n",
        "\n",
        "### 3.4.1 Defining the model architecture\n",
        "\n",
        "Now let's build our CNN architecture. We'll use a simple architecture with a few convolutional layers followed by fully connected layers. The model will take an input image of size 224x224 and output the probabilities for each of the 7 classes. Note the use of batch normalization, pooling, and dropout layers to improve the model's performance and prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sxCKvLhUMo9"
      },
      "outputs": [],
      "source": [
        "class SkinLesionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(SkinLesionCNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Batch normalization layers\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        # After 4 max-pooling operations with 224x224 input: 224/(2^4) = 14\n",
        "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First convolutional block\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "\n",
        "        # Second convolutional block\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "\n",
        "        # Third convolutional block\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        # Fourth convolutional block\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "\n",
        "        # Flatten the output\n",
        "        x = x.view(-1, 256 * 14 * 14)\n",
        "\n",
        "        # Fully connected layers with dropout\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zktcNPKcUMq3"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = SkinLesionCNN(num_classes=len(class_names))\n",
        "model = model.to(device)\n",
        "\n",
        "# Print model summary\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4.2 Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LsX56o6UMvK"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Train the model and evaluate on validation set after each epoch\n",
        "    \"\"\"\n",
        "    # Track best model\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = model.state_dict()\n",
        "\n",
        "    # Track loss and accuracy\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data\n",
        "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass + optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accs.append(epoch_acc.item())\n",
        "\n",
        "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # No gradient during validation\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(val_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
        "        val_losses.append(epoch_loss)\n",
        "        val_accs.append(epoch_acc.item())\n",
        "\n",
        "        print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        # Save the best model\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "        print()\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_losses, val_losses, train_accs, val_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96kY49g0Ubjo"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 15\n",
        "model, train_losses, val_losses, train_accs, val_accs = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'skin_lesion_cnn.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlRVrpkWUj04"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    \"\"\"\n",
        "    Evaluate model performance on the given dataloader\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "    return y_true, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beUoW-PTUj2Z"
      },
      "outputs": [],
      "source": [
        "y_true, y_pred = evaluate_model(model, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnNWFivvUj3h"
      },
      "outputs": [],
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF9Ip6LAUbn7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH2v9Bz_Uvju"
      },
      "source": [
        "### 3.4.3 Visualizing the results\n",
        "\n",
        "Let's visualize the training process and some predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2BtS-ZaUqoZ"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs+1), train_losses, 'b-', label='Training Loss')\n",
        "plt.plot(range(1, num_epochs+1), val_losses, 'r-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ6qb14-Uqqr"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs+1), train_accs, 'b-', label='Training Accuracy')\n",
        "plt.plot(range(1, num_epochs+1), val_accs, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6ueDY18Uzwg"
      },
      "outputs": [],
      "source": [
        "# Function to visualize predictions\n",
        "def visualize_predictions(model, dataloader, class_names, num_images=12):\n",
        "    \"\"\"\n",
        "    Visualize some predictions from the model\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    _ = plt.figure(figsize=(15, 10))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(3, 4, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'True: {class_names[labels[j]]}\\nPred: {class_names[preds[j]]}',\n",
        "                            color=('green' if preds[j] == labels[j] else 'red'))\n",
        "\n",
        "                # Denormalize image\n",
        "                img = inputs[j].cpu().numpy().transpose((1, 2, 0))\n",
        "                mean = np.array([0.485, 0.456, 0.406])\n",
        "                std = np.array([0.229, 0.224, 0.225])\n",
        "                img = std * img + mean\n",
        "                img = np.clip(img, 0, 1)\n",
        "\n",
        "                plt.imshow(img)\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                    return\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4UMlbKDU2vN"
      },
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "visualize_predictions(model, val_loader, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOS-QnqmU6P0"
      },
      "source": [
        "## 3.5 Making predictions\n",
        "\n",
        "Let's create a function to make predictions on new images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkrwaD_lU2xV"
      },
      "outputs": [],
      "source": [
        "def predict_image(model, image_path, transform, class_names):\n",
        "    \"\"\"\n",
        "    Make a prediction on a single image\n",
        "    \"\"\"\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        confidence, prediction = torch.max(probabilities, 1)\n",
        "\n",
        "    # Get prediction and confidence\n",
        "    predicted_class = class_names[prediction.item()]\n",
        "    confidence_score = confidence.item()\n",
        "\n",
        "    # Display image and prediction\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'Prediction: {predicted_class}\\nConfidence: {confidence_score:.4f}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Return all class probabilities\n",
        "    probs = probabilities.cpu().numpy()[0]\n",
        "    for i, (class_name, prob) in enumerate(zip(class_names, probs)):\n",
        "        print(f\"{class_name}: {prob:.4f}\")\n",
        "\n",
        "    return predicted_class, confidence_score\n",
        "\n",
        "# Example usage (replace with your image path)\n",
        "# predict_image(model, 'path_to_your_image.jpg', data_transforms['val'], class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.6 Simplifying with Pytorch lightning \n",
        "\n",
        "As we have seen in the previous chapters, PyTorch Lightning is a lightweight wrapper around PyTorch that helps to organize PyTorch code. It can as easily be used for CNNs as for other model types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "\n",
        "# Define a PyTorch Lightning module for the skin lesion CNN\n",
        "class LitSkinLesionCNN(pl.LightningModule):\n",
        "    def __init__(self, num_classes=7, lr=1e-3):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()  # Saves hyperparameters for logging and checkpointing\n",
        "        self.lr = lr\n",
        "\n",
        "        # Define the CNN architecture (same as before)\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the CNN\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Training step: computes loss and logs accuracy\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
        "        self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # Validation step: computes loss and logs accuracy\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
        "        self.log('val_acc', acc, on_step=False, on_epoch=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Define optimizer for training\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n",
        "# Example usage:\n",
        "# model = LitSkinLesionCNN(num_classes=len(class_names))\n",
        "# trainer = pl.Trainer(max_epochs=15, accelerator=\"auto\")\n",
        "# trainer.fit(model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.7 Optional exercise: Transfer learning \n",
        "\n",
        "Load the pretrained [resnet50](https://pytorch.org/hub/nvidia_deeplearningexamples_resnet50/) model and finetune it on the skin lesion dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNetTransferModel(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(ResNetTransferModel, self).__init__()\n",
        "        # Load pre-trained ResNet50\n",
        "        self.resnet = ...\n",
        "\n",
        "        # Freeze the early layers\n",
        "\n",
        "        # Replace the final fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initiailize the transfer learning model\n",
        "transfer_model = ResNetTransferModel(num_classes=len(class_names))\n",
        "transfer_model = transfer_model.to(device)\n",
        "\n",
        "# Define loss function and optimizer for the transfer learning model\n",
        "transfer_criterion = nn.CrossEntropyLoss()\n",
        "transfer_optimizer = optim.Adam(transfer_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Train the transfer learning model\n",
        "num_epochs_transfer = 10\n",
        "transfer_model, tl_train_losses, tl_val_losses, tl_train_accs, tl_val_accs = train_model(\n",
        "    transfer_model, train_loader, val_loader, transfer_criterion, transfer_optimizer, num_epochs_transfer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained transfer learning model\n",
        "torch.save(transfer_model.state_dict(), 'skin_lesion_transfer_learning.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the transfer learning model\n",
        "y_true_tl, y_pred_tl = evaluate_model(transfer_model, val_loader)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report (Transfer Learning):\")\n",
        "print(classification_report(y_true_tl, y_pred_tl, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_tl = confusion_matrix(y_true_tl, y_pred_tl)\n",
        "sns.heatmap(cm_tl, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (Transfer Learning)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compare the two models\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs+1), val_accs, 'b-', label='Custom CNN')\n",
        "plt.plot(range(1, num_epochs_transfer+1), tl_val_accs, 'r-', label='Transfer Learning')\n",
        "plt.title('Validation Accuracy Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs+1), val_losses, 'b-', label='Custom CNN')\n",
        "plt.plot(range(1, num_epochs_transfer+1), tl_val_losses, 'r-', label='Transfer Learning')\n",
        "plt.title('Validation Loss Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize predictions from the transfer learning model\n",
        "visualize_predictions(transfer_model, val_loader, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yhBxuduU5p8"
      },
      "outputs": [],
      "source": [
        "class ResNetTransferModel(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(ResNetTransferModel, self).__init__()\n",
        "        # Load pre-trained ResNet50\n",
        "        self.resnet = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "        # Freeze the early layers\n",
        "        for param in list(self.resnet.parameters())[:-20]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Replace the final fully connected layer\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "# Initialize the transfer learning model\n",
        "transfer_model = ResNetTransferModel(num_classes=len(class_names))\n",
        "transfer_model = transfer_model.to(device)\n",
        "\n",
        "# Define loss function and optimizer for the transfer learning model\n",
        "transfer_criterion = nn.CrossEntropyLoss()\n",
        "transfer_optimizer = optim.Adam(transfer_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Train the transfer learning model\n",
        "num_epochs_transfer = 10\n",
        "transfer_model, tl_train_losses, tl_val_losses, tl_train_accs, tl_val_accs = train_model(\n",
        "    transfer_model, train_loader, val_loader, transfer_criterion, transfer_optimizer, num_epochs_transfer\n",
        ")\n",
        "\n",
        "# Save the trained transfer learning model\n",
        "torch.save(transfer_model.state_dict(), 'skin_lesion_transfer_learning.pth')\n",
        "\n",
        "# Evaluate the transfer learning model\n",
        "y_true_tl, y_pred_tl = evaluate_model(transfer_model, val_loader)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report (Transfer Learning):\")\n",
        "print(classification_report(y_true_tl, y_pred_tl, target_names=class_names))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_tl = confusion_matrix(y_true_tl, y_pred_tl)\n",
        "sns.heatmap(cm_tl, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (Transfer Learning)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compare the two models\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs+1), val_accs, 'b-', label='Custom CNN')\n",
        "plt.plot(range(1, num_epochs_transfer+1), tl_val_accs, 'r-', label='Transfer Learning')\n",
        "plt.title('Validation Accuracy Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs+1), val_losses, 'b-', label='Custom CNN')\n",
        "plt.plot(range(1, num_epochs_transfer+1), tl_val_losses, 'r-', label='Transfer Learning')\n",
        "plt.title('Validation Loss Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize predictions from the transfer learning model\n",
        "visualize_predictions(transfer_model, val_loader, class_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
